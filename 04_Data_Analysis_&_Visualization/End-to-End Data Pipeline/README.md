# ğŸ§© End-to-End Data Pipeline

A fully automated **ETL (Extract, Transform, Load)** project in Python that simulates a production-grade data engineering workflow.

## ğŸš€ Features

âœ… Extracts data from CSV and API  
âœ… Cleans, transforms, and aggregates datasets  
âœ… Loads data into SQLite database  
âœ… Runs automated analysis queries  
âœ… Generates visualizations and summary report  

---

## ğŸ§± Project Structure

```
end_to_end_pipeline/
â”œâ”€â”€ main.py
â”œâ”€â”€ config/
â”‚ â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/sales_data.csv
â”‚ â””â”€â”€ processed/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ extract.py
â”‚ â”œâ”€â”€ transform.py
â”‚ â”œâ”€â”€ load.py
â”‚ â”œâ”€â”€ analyze.py
â”‚ â”œâ”€â”€ visualize.py
â”‚ â””â”€â”€ report_generator.py
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ db_utils.py
â”‚ â””â”€â”€ logger.py
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ figures/
â”‚ â””â”€â”€ reports/
â””â”€â”€ README.md
```

---

## ğŸ§° Tech Stack
```
- **Python 3.9+**
- **Pandas** â€” Data manipulation  
- **SQLite** â€” Lightweight database  
- **Matplotlib & Seaborn** â€” Visualization  
- **Requests** â€” API extraction (simulated)
```
Install dependencies:
```bash
pip install pandas matplotlib seaborn requests
```
ğŸ§® How It Works

1. Extract:
Reads CSV and API data â†’ converts to DataFrame.

2. Transform:
Cleans null values, validates schema, aggregates KPIs.

3. Load:
Stores clean data into SQLite (data_pipeline.db).

4. Analyze:
Computes summary metrics (revenue & quantity by region).

5. Visualize:
Plots a beautiful bar chart for total revenue per region.

6. Report:
Generates a summary text file with the results.

ğŸ“Š Example Output

Revenue by Region Chart:

Summary Report:

```
End-to-End Data Pipeline Report
========================================
Summary by Region:
Region       Total Revenue  Total Quantity
Europe            120000.0           5600
Asia               98000.0           4800
North America      75000.0           3900
```
ğŸ Run the Pipeline
```
python main.py
```
